{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69d521fa-9edd-476d-9555-d736dfbc2845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MLOps Pipeline automatizado\n",
    "\n",
    "### Este notebook se ejecutar√° como un scheduled job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3800d9d4-22da-41c4-84c3-be33b29de222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cddb2c8-3315-4936-a33b-c4dccc1bc8b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## 1. Cargar Modelo desde Registry\n",
    "\n",
    "def load_production_model(model_name: str):\n",
    "    \"\"\"Carga el modelo en Production desde el Registry\"\"\"\n",
    "    try:\n",
    "        model_uri = f\"models:/{model_name}@champion\"\n",
    "        model = mlflow.pyfunc.load_model(model_uri)\n",
    "        \n",
    "        client = MlflowClient()\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "model = load_production_model(\"wine_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb8d865e-06e2-422c-abe9-3dd75117242e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Cargar Nuevos Datos para Inferencia\n",
    "\n",
    "# Simular nuevos datos (en producci√≥n vendr√≠an de Delta Lake, S3, etc.)\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "new_data = pd.DataFrame(wine.data[:20], columns=wine.feature_names)\n",
    "\n",
    "print(f\"üìä Loaded {len(new_data)} records for inference\")\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3386b2c-3488-4916-9620-19f594277b5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Realizar Predicciones Batch\n",
    "\n",
    "# Inferencia\n",
    "predictions = model.predict(new_data)\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = new_data.copy()\n",
    "results_df['prediction'] = predictions\n",
    "results_df['inference_timestamp'] = datetime.now()\n",
    "\n",
    "print(f\"‚úÖ Generated {len(predictions)} predictions\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b8d094b-5d6c-400e-9517-196f03eea785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Guardar Resultados (Delta Lake)\n",
    "\n",
    "# Convertir a Spark DataFrame\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "results_spark_df = spark.createDataFrame(results_df)\n",
    "\n",
    "# Guardar en Delta Lake con merge\n",
    "\n",
    "catalog = \"workspace\"\n",
    "schema = \"default\"\n",
    "table = \"wine_predictions\"\n",
    "\n",
    "\n",
    "results_spark_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(f\"{catalog}.{schema}.{table}\")\n",
    "\n",
    "print(f\"üíæ Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35fd4448-bbed-4f09-8e5e-871bcccd4a90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Logging de la Corrida del Pipeline\n",
    "\n",
    "# Trackear la ejecuci√≥n del pipeline\n",
    "mlflow.set_experiment(\"/Users/your_username/wine_pipeline_production\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"batch_inference_{datetime.now().strftime('%Y%m%d_%H%M')}\"):\n",
    "    \n",
    "    # Metadata del pipeline\n",
    "    mlflow.log_param(\"model_name\", \"wine_classifier\")\n",
    "    mlflow.log_param(\"records_processed\", len(new_data))\n",
    "    mlflow.log_param(\"output_path\", output_path)\n",
    "    \n",
    "    # M√©tricas b√°sicas\n",
    "    mlflow.log_metric(\"num_predictions\", len(predictions))\n",
    "    mlflow.log_metric(\"execution_time_seconds\", 5)  # Calcular real\n",
    "    \n",
    "    # Distribuci√≥n de predicciones\n",
    "    prediction_distribution = pd.Series(predictions).value_counts().to_dict()\n",
    "    for class_label, count in prediction_distribution.items():\n",
    "        mlflow.log_metric(f\"class_{class_label}_count\", count)\n",
    "    \n",
    "    print(\"‚úÖ Pipeline execution logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01cd938e-d961-4c7e-aa52-ada3e1cead2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Validaciones y Alertas (Opcional)\n",
    "\n",
    "# Data drift detection simplificado\n",
    "def check_data_quality(df, threshold=0.95):\n",
    "    \"\"\"Validaci√≥n b√°sica de calidad\"\"\"\n",
    "    \n",
    "    # Check missing values\n",
    "    missing_pct = df.isnull().sum().max() / len(df)\n",
    "    \n",
    "    # Check prediction distribution\n",
    "    pred_distribution = df['prediction'].value_counts(normalize=True)\n",
    "    is_balanced = pred_distribution.max() < threshold\n",
    "    \n",
    "    if missing_pct > 0.1:\n",
    "        print(f\"‚ö†Ô∏è WARNING: {missing_pct*100:.2f}% missing values detected\")\n",
    "    \n",
    "    if not is_balanced:\n",
    "        print(f\"‚ö†Ô∏è WARNING: Imbalanced predictions detected\")\n",
    "        print(pred_distribution)\n",
    "    else:\n",
    "        print(\"‚úÖ Data quality checks passed\")\n",
    "    \n",
    "    return missing_pct < 0.1 and is_balanced\n",
    "\n",
    "quality_ok = check_data_quality(results_df)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"üéâ PIPELINE EXECUTION COMPLETED\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.2_jobs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
